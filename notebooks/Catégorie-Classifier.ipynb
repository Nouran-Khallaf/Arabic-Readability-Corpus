{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg-hHCYEX98V"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/refugies-info/genai-for-public-good/blob/main/notebooks/Catégorie-Classifier.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#**Simplification Typology Classifier using mBert**\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "l6kbJaSvdm8C"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This NoteBook is deticated to explore the use of pre-trained transformer-based models for multiclass text classification. The primary focus is on predicting the appropriate simplification strategies required to simplify respective SE sentences.\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Gh4FhylUgHbr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "> ### Load the data\n",
        "\n",
        "----\n"
      ],
      "metadata": {
        "id": "dcORk-xzd4EC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "!gdown \"https://drive.google.com/uc?id=1z-SRYUL6bAHQ-vfP0AJgxMjpkCd-56iP\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_iPKt2pEimIR",
        "outputId": "beb63bf8-f9af-4ad9-9fea-c7e22e975136"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.11/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.11/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from gdown) (3.17.0)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.11/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from gdown) (4.67.1)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.11/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (2024.12.14)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.11/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "Downloading...\n",
            "From: https://drive.google.com/uc?id=1z-SRYUL6bAHQ-vfP0AJgxMjpkCd-56iP\n",
            "To: /content/ri_annotated_texts_final.csv\n",
            "100% 76.8k/76.8k [00:00<00:00, 117MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "pnkGY9OMdWPq"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "file_path = 'ri_annotated_texts_final.csv'\n",
        "data = pd.read_csv(file_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "> ### Data Exploration and Analysis\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cZB0eau4kArg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Display basic information and first few rows\n",
        "data.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rHVVEMmSopzr",
        "outputId": "915da5a0-e444-42c1-d558-9471aeaa0c93"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 370 entries, 0 to 369\n",
            "Data columns (total 3 columns):\n",
            " #   Column             Non-Null Count  Dtype \n",
            "---  ------             --------------  ----- \n",
            " 0   Version initiale   370 non-null    object\n",
            " 1   Version retraitée  370 non-null    object\n",
            " 2   Catégorie          370 non-null    object\n",
            "dtypes: object(3)\n",
            "memory usage: 8.8+ KB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the first few rows of the dataset\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "DExzH-SRivJS",
        "outputId": "49476cb7-00f3-4268-ab8b-6ebd62ce7796"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                    Version initiale  \\\n",
              "0  Dispositif d'apprentissage du français : perme...   \n",
              "1  Dispositif d'apprentissage du français : perme...   \n",
              "2  Dispositif d'apprentissage du français : perme...   \n",
              "3  Dispositif d'apprentissage du français : perme...   \n",
              "4  Dispositif d'apprentissage du français : perme...   \n",
              "\n",
              "                                   Version retraitée     Catégorie  \n",
              "0  Des ateliers 2 fois par semaine pour progresse...   Explanation  \n",
              "1  Des ateliers 2 fois par semaine pour progresse...   Explanation  \n",
              "2  Des ateliers pour progresser en français, mieu...  Substitution  \n",
              "3  Des ateliers pour progresser en français, mieu...   Compression  \n",
              "4  Des ateliers pour progresser en français, mieu...     Syntactic  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7a2c1b7e-95f0-4ccd-8f6e-66690b3a5a0f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Version initiale</th>\n",
              "      <th>Version retraitée</th>\n",
              "      <th>Catégorie</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Dispositif d'apprentissage du français : perme...</td>\n",
              "      <td>Des ateliers 2 fois par semaine pour progresse...</td>\n",
              "      <td>Explanation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Dispositif d'apprentissage du français : perme...</td>\n",
              "      <td>Des ateliers 2 fois par semaine pour progresse...</td>\n",
              "      <td>Explanation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Dispositif d'apprentissage du français : perme...</td>\n",
              "      <td>Des ateliers pour progresser en français, mieu...</td>\n",
              "      <td>Substitution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Dispositif d'apprentissage du français : perme...</td>\n",
              "      <td>Des ateliers pour progresser en français, mieu...</td>\n",
              "      <td>Compression</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Dispositif d'apprentissage du français : perme...</td>\n",
              "      <td>Des ateliers pour progresser en français, mieu...</td>\n",
              "      <td>Syntactic</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7a2c1b7e-95f0-4ccd-8f6e-66690b3a5a0f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-7a2c1b7e-95f0-4ccd-8f6e-66690b3a5a0f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-7a2c1b7e-95f0-4ccd-8f6e-66690b3a5a0f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-d33ea4d7-bc4f-4976-892f-05ee56b14626\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-d33ea4d7-bc4f-4976-892f-05ee56b14626')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-d33ea4d7-bc4f-4976-892f-05ee56b14626 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 370,\n  \"fields\": [\n    {\n      \"column\": \"Version initiale\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 258,\n        \"samples\": [\n          \"L'inscription \\u00e0 la Mission Locale de Paris est n\\u00e9cessaire pour\\nb\\u00e9n\\u00e9ficier de l'action. L'accueil du public a lieu sur les 6 sites parisiens :\",\n          \"Nous vous rencontrons dans un des quartiers de la ville selon votre convenance : Adrien Pereira, Le Blosne, Centre\",\n          \"Permanence d'inscription\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Version retrait\\u00e9e\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 262,\n        \"samples\": [\n          \"- par mail : renardstephane@example.net\",\n          \"Apprendre le fran\\u00e7ais niveau d\\u00e9butant\",\n          \"Demander \\u00e0 un professionnel ou un b\\u00e9n\\u00e9vole\\nde nous contacter\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"Cat\\u00e9gorie\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 9,\n        \"samples\": [\n          \"Omission\",\n          \"Substitution\",\n          \"Transposition\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "```\n",
        "load important libiraries for visualisation\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "uTiSXUabrYC3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install seaborn wordcloud ace_tools"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zzrLpEQrUKT",
        "outputId": "4bd52508-0bbf-42fd-bd5b-fc74a2d09658"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.13.2)\n",
            "Requirement already satisfied: wordcloud in /usr/local/lib/python3.11/dist-packages (1.9.4)\n",
            "Collecting ace_tools\n",
            "  Downloading ace_tools-0.0-py3-none-any.whl.metadata (300 bytes)\n",
            "Requirement already satisfied: numpy!=1.24.0,>=1.20 in /usr/local/lib/python3.11/dist-packages (from seaborn) (1.26.4)\n",
            "Requirement already satisfied: pandas>=1.2 in /usr/local/lib/python3.11/dist-packages (from seaborn) (2.2.2)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in /usr/local/lib/python3.11/dist-packages (from seaborn) (3.10.0)\n",
            "Requirement already satisfied: pillow in /usr/local/lib/python3.11/dist-packages (from wordcloud) (11.1.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.55.7)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.2->seaborn) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
            "Downloading ace_tools-0.0-py3-none-any.whl (1.1 kB)\n",
            "Installing collected packages: ace_tools\n",
            "Successfully installed ace_tools-0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from collections import Counter\n",
        "from wordcloud import WordCloud"
      ],
      "metadata": {
        "id": "At8Gusygo4Lf"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Distribution of Simplification Strategies\n",
        "\n"
      ],
      "metadata": {
        "id": "9g3ZvM5So8s-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotly bar chart for distribution of categories\n",
        "fig = px.bar(data['Catégorie'].value_counts().reset_index(),\n",
        "             x='Catégorie',\n",
        "             y='count',\n",
        "             labels={'Catégorie': 'Simplification Strategy', 'count': 'Count'},  # Updated labels\n",
        "             title='Distribution of Simplification Strategies')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "LfA-ayi3o8fx",
        "outputId": "d049e23b-1478-4754-a96b-358cfd88e7fc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"ca008d3e-1e9d-462f-9137-2630bb92867c\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"ca008d3e-1e9d-462f-9137-2630bb92867c\")) {                    Plotly.newPlot(                        \"ca008d3e-1e9d-462f-9137-2630bb92867c\",                        [{\"alignmentgroup\":\"True\",\"hovertemplate\":\"Simplification Strategy=%{x}\\u003cbr\\u003eCount=%{y}\\u003cextra\\u003e\\u003c\\u002fextra\\u003e\",\"legendgroup\":\"\",\"marker\":{\"color\":\"#636efa\",\"pattern\":{\"shape\":\"\"}},\"name\":\"\",\"offsetgroup\":\"\",\"orientation\":\"v\",\"showlegend\":false,\"textposition\":\"auto\",\"x\":[\"Explanation\",\"Substitution\",\"Transcription\",\"Syntactic\",\"Modulation\",\"Transposition\",\"Compression\",\"Omission\",\"Synonymy\"],\"xaxis\":\"x\",\"y\":[92,73,54,50,43,24,17,14,3],\"yaxis\":\"y\",\"type\":\"bar\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"xaxis\":{\"anchor\":\"y\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Simplification Strategy\"}},\"yaxis\":{\"anchor\":\"x\",\"domain\":[0.0,1.0],\"title\":{\"text\":\"Count\"}},\"legend\":{\"tracegroupgap\":0},\"title\":{\"text\":\"Distribution of Simplification Strategies\"},\"barmode\":\"relative\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('ca008d3e-1e9d-462f-9137-2630bb92867c');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Text Length Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "1uq3HnqspYZF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data['Initial_Length'] = data['Version initiale'].apply(len)\n",
        "data['Retraited_Length'] = data['Version retraitée'].apply(len)\n",
        "\n",
        "# Plotly histogram for text length comparison\n",
        "fig = go.Figure()\n",
        "fig.add_trace(go.Histogram(x=data['Initial_Length'], name='Original Text Length', opacity=0.6))\n",
        "fig.add_trace(go.Histogram(x=data['Retraited_Length'], name='Simplified Text Length', opacity=0.6))\n",
        "fig.update_layout(title='Distribution of Text Lengths Before and After Simplification',\n",
        "                  xaxis_title='Text Length', yaxis_title='Frequency',\n",
        "                  barmode='overlay')\n",
        "fig.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 542
        },
        "id": "8-kLbB-UpKwM",
        "outputId": "2452ba82-04ea-4787-cace-0a95475483af"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax && window.MathJax.Hub && window.MathJax.Hub.Config) {window.MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script charset=\"utf-8\" src=\"https://cdn.plot.ly/plotly-2.35.2.min.js\"></script>                <div id=\"d2718bb3-d415-4c8c-8282-e58f05a42770\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"d2718bb3-d415-4c8c-8282-e58f05a42770\")) {                    Plotly.newPlot(                        \"d2718bb3-d415-4c8c-8282-e58f05a42770\",                        [{\"name\":\"Original Text Length\",\"opacity\":0.6,\"x\":[167,167,167,167,167,22,124,124,19,145,145,145,145,33,200,200,200,52,52,191,191,191,24,164,28,28,28,29,39,27,50,34,33,105,105,34,15,46,30,30,41,21,52,29,27,48,20,20,32,44,155,155,15,62,62,14,100,100,29,40,40,101,101,112,112,29,124,124,17,114,31,139,21,30,30,34,39,48,148,148,148,110,111,111,111,56,110,110,32,150,150,150,179,179,120,50,50,165,165,165,159,43,141,141,141,246,246,246,80,80,80,46,228,228,36,36,109,109,321,321,83,83,228,228,228,228,165,165,165,27,27,20,42,150,150,78,78,78,66,249,249,85,85,85,36,36,241,241,14,14,14,31,81,13,140,32,58,46,172,254,254,65,13,34,28,58,49,49,36,43,90,39,110,110,142,142,142,35,18,73,59,186,86,40,292,98,26,193,57,194,194,21,169,169,14,14,355,50,207,207,96,25,129,54,51,61,55,43,39,43,35,77,56,58,27,27,45,64,31,70,97,25,108,42,195,195,21,26,56,41,42,14,158,158,105,99,61,137,64,44,44,40,39,11,11,59,59,59,59,16,35,35,18,260,260,260,57,57,27,106,105,105,105,62,40,87,34,39,48,37,72,72,45,38,102,142,142,73,73,74,74,72,72,147,111,111,111,63,96,47,48,65,52,135,135,135,55,45,77,40,33,64,70,57,21,7,67,24,36,36,93,93,69,67,130,130,71,52,19,50,17,116,116,116,34,34,123,123,123,157,36,88,88,15,92,18,186,48,120,120,54,100,176,176,54,65,32,52,49,22,25,35,58,58,58,29,53,55,48,15,47,47,151,115,115,69,124,124,124,59],\"type\":\"histogram\"},{\"name\":\"Simplified Text Length\",\"opacity\":0.6,\"x\":[216,124,105,105,105,22,130,130,19,164,164,164,164,33,177,177,47,38,38,168,168,168,40,153,63,63,63,107,62,67,79,35,138,235,235,194,22,132,35,72,50,21,55,54,92,56,41,41,94,72,84,84,26,90,90,26,153,153,61,86,86,175,175,57,57,60,287,287,51,128,50,114,21,94,94,36,40,50,109,109,109,103,81,81,81,59,189,189,43,112,112,112,110,110,121,36,36,200,200,200,167,39,194,194,194,385,385,385,266,266,266,94,114,114,40,40,55,55,129,129,36,36,114,114,114,114,108,108,108,41,41,76,39,234,234,36,249,249,49,180,180,191,191,191,40,40,116,116,89,89,89,68,84,32,74,150,176,59,85,168,168,25,38,60,48,67,40,40,232,29,92,35,130,130,196,196,196,86,33,129,53,291,192,40,271,98,26,203,57,173,173,21,150,150,42,42,202,41,84,84,75,58,137,53,75,61,55,43,34,69,50,76,59,58,43,27,48,52,31,70,97,25,108,42,218,218,21,26,56,41,42,32,196,196,108,100,60,137,64,34,34,40,97,33,33,93,93,93,93,29,64,64,19,174,174,174,73,73,46,177,114,114,114,82,40,73,34,39,40,66,104,104,24,39,110,122,122,42,42,102,102,75,75,143,60,224,224,63,96,47,48,65,52,152,152,152,122,45,77,40,33,64,72,57,21,7,67,24,37,37,85,85,63,32,90,90,74,47,230,49,18,96,96,96,43,43,121,121,121,137,27,99,99,28,107,44,100,46,72,72,56,72,178,177,30,62,54,63,20,49,35,39,155,128,128,14,45,35,45,26,52,52,117,102,102,43,119,119,119,43],\"type\":\"histogram\"}],                        {\"template\":{\"data\":{\"histogram2dcontour\":[{\"type\":\"histogram2dcontour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"choropleth\":[{\"type\":\"choropleth\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"histogram2d\":[{\"type\":\"histogram2d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmap\":[{\"type\":\"heatmap\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"heatmapgl\":[{\"type\":\"heatmapgl\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"contourcarpet\":[{\"type\":\"contourcarpet\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"contour\":[{\"type\":\"contour\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"surface\":[{\"type\":\"surface\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"},\"colorscale\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]]}],\"mesh3d\":[{\"type\":\"mesh3d\",\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}],\"scatter\":[{\"fillpattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2},\"type\":\"scatter\"}],\"parcoords\":[{\"type\":\"parcoords\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolargl\":[{\"type\":\"scatterpolargl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"bar\":[{\"error_x\":{\"color\":\"#2a3f5f\"},\"error_y\":{\"color\":\"#2a3f5f\"},\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"bar\"}],\"scattergeo\":[{\"type\":\"scattergeo\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterpolar\":[{\"type\":\"scatterpolar\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"histogram\":[{\"marker\":{\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"histogram\"}],\"scattergl\":[{\"type\":\"scattergl\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatter3d\":[{\"type\":\"scatter3d\",\"line\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattermapbox\":[{\"type\":\"scattermapbox\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scatterternary\":[{\"type\":\"scatterternary\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"scattercarpet\":[{\"type\":\"scattercarpet\",\"marker\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}}}],\"carpet\":[{\"aaxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"baxis\":{\"endlinecolor\":\"#2a3f5f\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"minorgridcolor\":\"white\",\"startlinecolor\":\"#2a3f5f\"},\"type\":\"carpet\"}],\"table\":[{\"cells\":{\"fill\":{\"color\":\"#EBF0F8\"},\"line\":{\"color\":\"white\"}},\"header\":{\"fill\":{\"color\":\"#C8D4E3\"},\"line\":{\"color\":\"white\"}},\"type\":\"table\"}],\"barpolar\":[{\"marker\":{\"line\":{\"color\":\"#E5ECF6\",\"width\":0.5},\"pattern\":{\"fillmode\":\"overlay\",\"size\":10,\"solidity\":0.2}},\"type\":\"barpolar\"}],\"pie\":[{\"automargin\":true,\"type\":\"pie\"}]},\"layout\":{\"autotypenumbers\":\"strict\",\"colorway\":[\"#636efa\",\"#EF553B\",\"#00cc96\",\"#ab63fa\",\"#FFA15A\",\"#19d3f3\",\"#FF6692\",\"#B6E880\",\"#FF97FF\",\"#FECB52\"],\"font\":{\"color\":\"#2a3f5f\"},\"hovermode\":\"closest\",\"hoverlabel\":{\"align\":\"left\"},\"paper_bgcolor\":\"white\",\"plot_bgcolor\":\"#E5ECF6\",\"polar\":{\"bgcolor\":\"#E5ECF6\",\"angularaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"radialaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"ternary\":{\"bgcolor\":\"#E5ECF6\",\"aaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"baxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"},\"caxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\"}},\"coloraxis\":{\"colorbar\":{\"outlinewidth\":0,\"ticks\":\"\"}},\"colorscale\":{\"sequential\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"sequentialminus\":[[0.0,\"#0d0887\"],[0.1111111111111111,\"#46039f\"],[0.2222222222222222,\"#7201a8\"],[0.3333333333333333,\"#9c179e\"],[0.4444444444444444,\"#bd3786\"],[0.5555555555555556,\"#d8576b\"],[0.6666666666666666,\"#ed7953\"],[0.7777777777777778,\"#fb9f3a\"],[0.8888888888888888,\"#fdca26\"],[1.0,\"#f0f921\"]],\"diverging\":[[0,\"#8e0152\"],[0.1,\"#c51b7d\"],[0.2,\"#de77ae\"],[0.3,\"#f1b6da\"],[0.4,\"#fde0ef\"],[0.5,\"#f7f7f7\"],[0.6,\"#e6f5d0\"],[0.7,\"#b8e186\"],[0.8,\"#7fbc41\"],[0.9,\"#4d9221\"],[1,\"#276419\"]]},\"xaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"yaxis\":{\"gridcolor\":\"white\",\"linecolor\":\"white\",\"ticks\":\"\",\"title\":{\"standoff\":15},\"zerolinecolor\":\"white\",\"automargin\":true,\"zerolinewidth\":2},\"scene\":{\"xaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"yaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2},\"zaxis\":{\"backgroundcolor\":\"#E5ECF6\",\"gridcolor\":\"white\",\"linecolor\":\"white\",\"showbackground\":true,\"ticks\":\"\",\"zerolinecolor\":\"white\",\"gridwidth\":2}},\"shapedefaults\":{\"line\":{\"color\":\"#2a3f5f\"}},\"annotationdefaults\":{\"arrowcolor\":\"#2a3f5f\",\"arrowhead\":0,\"arrowwidth\":1},\"geo\":{\"bgcolor\":\"white\",\"landcolor\":\"#E5ECF6\",\"subunitcolor\":\"white\",\"showland\":true,\"showlakes\":true,\"lakecolor\":\"white\"},\"title\":{\"x\":0.05},\"mapbox\":{\"style\":\"light\"}}},\"title\":{\"text\":\"Distribution of Text Lengths Before and After Simplification\"},\"xaxis\":{\"title\":{\"text\":\"Text Length\"}},\"yaxis\":{\"title\":{\"text\":\"Frequency\"}},\"barmode\":\"overlay\"},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('d2718bb3-d415-4c8c-8282-e58f05a42770');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Word Frequency Analysis\n",
        "\n"
      ],
      "metadata": {
        "id": "ZvxXvqIOp0-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "nltk.download('punkt_tab')\n",
        "\n",
        "stop_words = set(stopwords.words('french'))\n",
        "\n",
        "def get_most_common_words(text_series, n=20):\n",
        "    words = ' '.join(text_series).lower()\n",
        "    words = nltk.word_tokenize(words)\n",
        "    words = [word for word in words if word.isalnum() and word not in stop_words]\n",
        "    return Counter(words).most_common(n)\n",
        "\n",
        "# Display top words\n",
        "print(\"Top words in Original Text:\", get_most_common_words(data['Version initiale']))\n",
        "print(\"Top words in Simplified Text:\", get_most_common_words(data['Version retraitée']))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wzC6khQmpgCN",
        "outputId": "bf618930-eb0a-47f5-b0b7-778449ba8a03"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top words in Original Text: [('français', 67), ('travail', 36), ('formation', 29), ('comprendre', 25), ('france', 22), ('ateliers', 21), ('vie', 21), ('langue', 20), ('accompagnement', 20), ('cours', 19), ('faire', 19), ('professionnelle', 18), ('apprendre', 18), ('démarches', 18), ('savoir', 15), ('niveau', 15), ('besoins', 15), ('mail', 14), ('personnes', 14), ('vocabulaire', 13)]\n",
            "Top words in Simplified Text: [('français', 62), ('travail', 59), ('apprendre', 39), ('trouver', 35), ('formation', 30), ('comprendre', 28), ('être', 28), ('démarches', 27), ('mieux', 25), ('ateliers', 24), ('faire', 24), ('professionnel', 23), ('connaître', 23), ('pouvez', 23), ('niveau', 23), ('communiquer', 22), ('accompagnement', 21), ('mail', 20), ('savoir', 19), ('prendre', 19)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get top words and their frequencies\n",
        "original_top_words = get_most_common_words(data['Version initiale'])\n",
        "simplified_top_words = get_most_common_words(data['Version retraitée'])\n",
        "\n",
        "# Convert to DataFrame for better visualization\n",
        "df_words = pd.DataFrame({\n",
        "    \"Word (Original)\": [word for word, _ in original_top_words],\n",
        "    \"Frequency (Original)\": [freq for _, freq in original_top_words],\n",
        "    \"Word (Simplified)\": [word for word, _ in simplified_top_words],\n",
        "    \"Frequency (Simplified)\": [freq for _, freq in simplified_top_words],\n",
        "})"
      ],
      "metadata": {
        "id": "88ahQXykvR9G"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "fig, ax = plt.subplots(figsize=(10, 5))\n",
        "ax.barh([word for word, _ in original_top_words], [freq for _, freq in original_top_words], color='blue', alpha=0.6, label=\"Original Text\")\n",
        "ax.barh([word for word, _ in simplified_top_words], [freq for _, freq in simplified_top_words], color='red', alpha=0.6, label=\"Simplified Text\")\n",
        "\n",
        "ax.set_xlabel(\"Frequency\")\n",
        "ax.set_ylabel(\"Words\")\n",
        "ax.set_title(\"Top Words in Original vs Simplified Text\")\n",
        "ax.legend()\n",
        "\n",
        "plt.gca().invert_yaxis()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "lJg0S-Jdvj24",
        "outputId": "245377aa-1e6d-4def-98e4-7719c1a53583"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> Add blockquote\n",
        "\n"
      ],
      "metadata": {
        "id": "yZVc_XJheQql"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure the relevant columns are present\n",
        "assert 'Version initiale' in data.columns and 'Version retraitée' in data.columns, \"Required columns missing.\"\n",
        "\n",
        "# Calculate sentence lengths (number of words per sentence) for complex and simple texts\n",
        "data['Standard_Length'] = data['Version initiale'].str.split().str.len()\n",
        "data['E2R_Length'] = data['Version retraitée'].str.split().str.len()\n",
        "\n",
        "# Calculate total number of words in each column\n",
        "total_words_complex = data['Standard_Length'].sum()\n",
        "total_words_simple = data['E2R_Length'].sum()\n",
        "\n",
        "# Compute ranges and interquartile ranges for \"Complex\" (Version initiale) texts\n",
        "complex_q1 = data['Standard_Length'].quantile(0.25)\n",
        "complex_q3 = data['Standard_Length'].quantile(0.75)\n",
        "complex_iqr = complex_q3 - complex_q1\n",
        "\n",
        "# Compute ranges and interquartile ranges for \"Simple\" (E2R version) texts\n",
        "simple_q1 = data['E2R_Length'].quantile(0.25)\n",
        "simple_q3 = data['E2R_Length'].quantile(0.75)\n",
        "simple_iqr = simple_q3 - simple_q1\n",
        "\n",
        "# Display the results\n",
        "print(\"Complex Texts (Version initiale):\")\n",
        "print(f\"Total Number of Words: {total_words_complex}\")\n",
        "print(f\"Range at 25th Percentile (Q1): {complex_q1} words\")\n",
        "print(f\"Range at 75th Percentile (Q3): {complex_q3} words\")\n",
        "print(f\"IQR: {complex_iqr} words\\n\")\n",
        "\n",
        "print(\"Simplified Texts (Version retraitée):\")\n",
        "print(f\"Total Number of Words: {total_words_simple}\")\n",
        "print(f\"Range at 25th Percentile (Q1): {simple_q1} words\")\n",
        "print(f\"Range at 75th Percentile (Q3): {simple_q3} words\")\n",
        "print(f\"IQR: {simple_iqr} words\")"
      ],
      "metadata": {
        "id": "EcDzNmHSe3z5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "178c47d7-9806-4e24-d02e-f43c0e6982b1"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Complex Texts (Version initiale):\n",
            "Total Number of Words: 5005\n",
            "Range at 25th Percentile (Q1): 6.0 words\n",
            "Range at 75th Percentile (Q3): 19.0 words\n",
            "IQR: 13.0 words\n",
            "\n",
            "Simplified Texts (Version retraitée):\n",
            "Total Number of Words: 5647\n",
            "Range at 25th Percentile (Q1): 7.0 words\n",
            "Range at 75th Percentile (Q3): 20.0 words\n",
            "IQR: 13.0 words\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "\n",
        "# Enhanced visualization with boxplots\n",
        "plt.figure(figsize=(10, 6))\n",
        "sns.boxplot(data=data[['Standard_Length', 'E2R_Length']], palette=[\"blue\", \"red\"])\n",
        "plt.xticks(ticks=[0, 1], labels=[\"Complex Texts\", \"Simplified Texts\"])\n",
        "plt.ylabel(\"Sentence Length (Word Count)\")\n",
        "plt.title(\"Distribution of Sentence Lengths: Complex vs Simplified Texts\")\n",
        "plt.grid(True)\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 545
        },
        "id": "FjG0ECT_y8pi",
        "outputId": "3310b3b4-867b-427e-f508-20daa3d5cb62"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "> ### Install Hugging Face Transformers and Datasets library\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "wGmdXwc1hD47"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers datasets torch"
      ],
      "metadata": {
        "id": "cnQyuc0teWdr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cbf28a6-840a-49ea-dff6-972fd8721a46"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.47.1)\n",
            "Collecting datasets\n",
            "  Downloading datasets-3.2.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Collecting xxhash (from datasets)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.9.0,>=2023.1.0 (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets)\n",
            "  Downloading fsspec-2024.9.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.11)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2024.12.14)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Downloading datasets-3.2.0-py3-none-any.whl (480 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m105.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m85.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m20.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m19.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.9.0-py3-none-any.whl (179 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m15.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xxhash, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, fsspec, dill, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, nvidia-cusolver-cu12, datasets\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2024.9.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.2.0 dill-0.3.8 fsspec-2024.9.0 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 xxhash-3.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        ")\n",
        "from datasets import Dataset\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from torch.utils.data import WeightedRandomSampler\n",
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    pipeline\n",
        ")\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score"
      ],
      "metadata": {
        "id": "whdhc03wmJAP"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "> Data Prepration\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "GpkGr0y5tcth"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare the dataset\n",
        "data = data.dropna(subset=['Version initiale', 'Version retraitée', 'Catégorie'])  # Drop rows with missing values\n",
        "X = data[['Version initiale', 'Version retraitée']].values  # Both text inputs\n",
        "y = data['Catégorie'].tolist()\n",
        "\n",
        "# Encode labels\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "# Combine Standard French and E2R version with a separator\n",
        "def combine_texts(row):\n",
        "    return f\"Standard French: {row[0]} [SEP] E2R Version: {row[1]}\"\n",
        "\n",
        "X_combined = [combine_texts(row) for row in X]\n",
        "\n",
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    X_combined, y_encoded, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Train-test split\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_texts, val_texts, train_typologies, val_typologies = train_test_split(\n",
        "    X_combined, y, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "# Show dataset statistics\n",
        "print(f\"Training samples: {len(train_texts)}\")\n",
        "print(f\"Validation samples: {len(val_texts)}\")"
      ],
      "metadata": {
        "id": "2EOK-SoIeiYV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5764aebf-0bb9-445b-9ab6-f351d97c7279"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training samples: 296\n",
            "Validation samples: 74\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "> # Fine-tune the Model\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "cfXgB98jx-L3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "## **1. Data Preparation: Cleaning and Formatting the Dataset**\n",
        "Before training, we **preprocess the dataset** by:\n",
        "1. **Handling Missing Values**: Dropping any missing values in the key columns (`Version initiale` and `Catégorie`).\n",
        "   ```python\n",
        "   data = data.dropna(subset=['Version initiale', 'Catégorie'])\n",
        "   ```\n",
        "2. **Cleaning the Typology Column**: Removing **non-breaking spaces (`\\xa0`)** and regular spaces to standardize labels.\n",
        "   ```python\n",
        "   data['Typology'] = data['Catégorie'].str.replace(\"\\xa0\", \"\").str.replace(\" \", \"\")\n",
        "   ```\n",
        "3. **Encoding Typologies**: Using `LabelEncoder` to convert category labels into numerical values for the model.\n",
        "   ```python\n",
        "   label_encoder = LabelEncoder()\n",
        "   data['Typology Encoded'] = label_encoder.fit_transform(data['Typology'])\n",
        "   ```\n",
        "\n",
        "✅ **Why?**  \n",
        "- Ensures the dataset is clean and structured before augmentation and model training.\n",
        "- Helps the model recognize category labels in a numerical format.\n",
        "\n",
        "---\n",
        "\n",
        "## **2. Data Augmentation: Addressing Class Imbalance**\n",
        "To **balance underrepresented categories**, we apply **text augmentation** using a **T5-small paraphraser model**:\n",
        "To improve model performance on underrepresented categories, we applied text  The process follows these steps:\n",
        "\n",
        "- Identify the three least frequent categories in the dataset.\n",
        "- Use a **text-to-text generation model (`t5-small`)** to paraphrase sentences from these categories.\n",
        "- Generate one new paraphrased version for each text sample.\n",
        "- Append the newly augmented data to the original dataset.\n",
        "- Re-encode the typologies after augmentation to maintain consistency.\n",
        "\n",
        "✅ This step ensures that the model gets a balanced representation of all categories, leading to better generalization.\n",
        "\n",
        "1. Identify the **three least frequent classes** in the dataset.\n",
        "   ```python\n",
        "   underrepresented_classes = data['Catégorie'].value_counts().tail(3).index.tolist()\n",
        "   ```\n",
        "2. Use `t5-small` for paraphrasing:\n",
        "   ```python\n",
        "   paraphraser = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
        "   ```\n",
        "3. Generate **augmented text** for samples in these classes:\n",
        "   ```python\n",
        "   def augment_text(text):\n",
        "       augmented = paraphraser(text, max_length=100, num_return_sequences=1)\n",
        "       return augmented[0]['generated_text']\n",
        "   ```\n",
        "4. Add augmented samples to the dataset:\n",
        "   ```python\n",
        "   augmented_data = []\n",
        "   for typology in underrepresented_classes:\n",
        "       class_data = data[data['Typology'] == typology]\n",
        "       for _, row in class_data.iterrows():\n",
        "           augmented_text = augment_text(row['Version initiale'])\n",
        "           augmented_data.append({'Version initiale': augmented_text, 'Typology': typology})\n",
        "\n",
        "   augmented_df = pd.DataFrame(augmented_data)\n",
        "   data = pd.concat([data, augmented_df], ignore_index=True)\n",
        "   ```\n",
        "\n",
        "✅ **Why?**  \n",
        "- Ensures the model **does not ignore** rare categories.\n",
        "- Generates **synthetic training data** to balance class distribution.\n",
        "\n",
        "---\n",
        "\n",
        "## **3. Applying Stratified K-Fold Cross-Validation**\n",
        "Instead of a **single train-test split**, we use **5-fold stratified cross-validation**: (with `n_splits=5`) to make the training process more robust.\n",
        "```python\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "```\n",
        "### **Process:**\n",
        "- **Splits data into 5 subsets** while preserving the class distribution.\n",
        "- Trains on 4 subsets and **validates on the remaining subset**.\n",
        "- **Repeats 5 times** (each subset gets a turn as the validation set).\n",
        "- Compute **average accuracy, precision, recall, and F1-score** across all folds.\n",
        "\n",
        "✅ **Why?**  \n",
        "- Prevents **biased model performance** due to unlucky data splits.\n",
        "- Ensures **robust evaluation** across different subsets.\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "## **4. Training Arguments for Optimized Model Performance**\n",
        "We define **custom training arguments** using `TrainingArguments`:\n",
        "- `output_dir`: Saves the model checkpoints for each fold.\n",
        "- `evaluation_strategy=\"epoch\"`: Evaluates the model after every epoch.\n",
        "- `save_strategy=\"epoch\"`: Saves the model at the end of each epoch.\n",
        "- `learning_rate=5e-5`: A standard learning rate for fine-tuning transformers.\n",
        "- `per_device_train_batch_size=8`: Small batch size to fit into GPU memory.\n",
        "- `num_train_epochs=3`: Trains for 3 epochs to prevent overfitting.\n",
        "- `weight_decay=0.01`: Helps with regularization.\n",
        "- `load_best_model_at_end=True`: Ensures that the best version of the model is kept.\n",
        "```python\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=f\"./results/{model_name}_fold_{fold}\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    save_strategy=\"epoch\",\n",
        "    learning_rate=5e-6,\n",
        "    per_device_train_batch_size=8,\n",
        "    per_device_eval_batch_size=8,\n",
        "    num_train_epochs=5,  # More epochs, but early stopping prevents overfitting\n",
        "    weight_decay=0.01,\n",
        "    logging_dir=f\"./logs/{model_name}_fold_{fold}\",\n",
        "    save_total_limit=2,\n",
        "    load_best_model_at_end=True,\n",
        "    gradient_accumulation_steps=1,\n",
        "    fp16=True,  # Mixed precision training for efficiency\n",
        "    gradient_checkpointing=True,  # Reduces memory consumption\n",
        "    max_grad_norm=1.0  # Prevents exploding gradients\n",
        ")\n",
        "```\n",
        "Additionally, we use **Early Stopping** to halt training when the model stops improving:\n",
        "```python\n",
        "callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "```\n",
        "\n",
        "✅ **Why?**  \n",
        "- **Efficient GPU usage** with mixed precision (`fp16`) and gradient checkpointing.\n",
        "- **Prevents overfitting** by stopping training early when improvement slows.\n",
        "\n",
        "---\n",
        "\n",
        "## **5. Model Training and Evaluation**\n",
        "For each fold:\n",
        "- **Tokenize input data** and prepare `torch.tensor` datasets.\n",
        "- **Train the model** using the custom `Trainer`:\n",
        "  ```python\n",
        "  trainer = CustomTrainer(\n",
        "      model=model,\n",
        "      args=training_args,\n",
        "      train_dataset=train_dataset,\n",
        "      eval_dataset=val_dataset,\n",
        "      data_collator=data_collator,\n",
        "      compute_metrics=compute_metrics,\n",
        "      callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]\n",
        "  )\n",
        "  ```\n",
        "- **Evaluate and store results** after each epoch:\n",
        "  ```python\n",
        "  evaluation_results = trainer.evaluate()\n",
        "  ```\n",
        "\n",
        "✅ **Why?**  \n",
        "- Automates training and validation for **multiple models**.\n",
        "- Captures **detailed per-epoch and per-fold performance**.\n",
        "\n",
        "---\n",
        "\n",
        "## **6. Storing and Analyzing Model Results**\n",
        "### **Saving Model Performance:**\n",
        "- **Final aggregated results per model**:\n",
        "  ```python\n",
        "  final_results_df = pd.DataFrame(all_model_results)\n",
        "  final_results_df.to_csv(\"complex_model_results.csv\", index=False)\n",
        "  ```\n",
        "- **Detailed per-fold and per-epoch results**:\n",
        "  ```python\n",
        "  detailed_results_df = pd.DataFrame(detailed_results)\n",
        "  detailed_results_df.to_csv(\"Complex_detailed_model_results.csv\", index=False)\n",
        "  ```\n",
        "- **Summarized aggregated performance**:\n",
        "  ```python\n",
        "  aggregated_summary_df = pd.DataFrame(aggregated_summary)\n",
        "  aggregated_summary_df.to_csv(\"Complex_aggregated_model_summary.csv\", index=False)\n",
        "  ```\n",
        "\n",
        "✅ **Why?**  \n",
        "- Enables **post-training analysis** to compare models and optimize hyperparameters.\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "jgAqJcbthW-y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> # Model #1 Standared+E2R\n",
        "\n"
      ],
      "metadata": {
        "id": "tq84cbQGi-NG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `**This model only Combining Standard and Easy-to-Read (E2R) and the \"Categories\" for classification.**`\n"
      ],
      "metadata": {
        "id": "b8PZOdzMk1S4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### ** Data Preparation: Combining Standard and Easy-to-Read (E2R) Versions**  \n",
        "\n",
        "To create a **single input format** for the model, we merged two versions of the text:  \n",
        "- **Standard Version** (e.g., formal or original text)  \n",
        "- **Easy-to-Read (E2R) Version** (a simplified or adapted version for better comprehension)  \n",
        "\n",
        "#### **How We Combined Them:**  \n",
        "For each data entry, we structured the input text as:  \n",
        "\n",
        "```python\n",
        "data['Combined Text'] = data.apply(\n",
        "    lambda row: f\"Standard French: {row['Version initiale']} [SEP] Easy-to-Read: {row['Version retraitée']}\",\n",
        "    axis=1\n",
        ")\n",
        "```\n",
        "This approach:  \n",
        "✅ **Provides Context**: The model learns relationships between the original and simplified versions.  \n",
        "✅ **Ensures Uniform Input Format**: The `[SEP]` token helps the transformer model differentiate between the two parts of the text.  \n",
        "✅ **Enhances Learning**: By seeing both versions together, the model better understands variations in language complexity.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "5tyDoH1UfSK4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "### Model Description:\n",
        "This script performs text classification using transformer-based models to categorize text into different typologies.\n",
        "It follows these key steps:\n",
        "1. **Data Preparation**: Combining Standard and Easy-to-Read (E2R) versions of text to create a single input format.\n",
        "2. **Handling Class Imbalance**: Augmenting underrepresented categories using a text paraphraser.\n",
        "3. **Model Training**: Fine-tuning transformer-based models (e.g., BERT) with stratified k-fold cross-validation.\n",
        "4. **Evaluation**: Assessing model performance using accuracy, F1-score, precision, and recall.\n",
        "5. **Model Saving**: Storing the trained models for future inference.\n",
        "\n",
        "This approach ensures robust training and better generalization by leveraging data augmentation and cross-validation techniques.\n",
        "\"\"\"\n",
        "\n",
        "# Import Required Libraries\n",
        "import torch\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments, DataCollatorWithPadding, pipeline\n",
        "\n",
        "# Data Preprocessing and Augmentation\n",
        "print(\"Loading and preparing the dataset...\")\n",
        "\n",
        "# Combine \"Standard English\" and \"E2R Version\" for input\n",
        "data['Combined Text'] = data.apply(\n",
        "    lambda row: f\"Standard French: {row['Version initiale']} [SEP] Easy-to-Read: {row['Version retraitée']}\", axis=1\n",
        ")\n",
        "data = data.dropna(subset=['Combined Text', 'Catégorie'])\n",
        "\n",
        "# Encode Typologies\n",
        "label_encoder = LabelEncoder()\n",
        "data['Typology Encoded'] = label_encoder.fit_transform(data['Catégorie'])\n",
        "\n",
        "# Handle Class Imbalance with Augmentation\n",
        "underrepresented_classes = data['Catégorie'].value_counts().tail(3).index.tolist()\n",
        "paraphraser = pipeline(\"text2text-generation\", model=\"t5-small\", device=0 if torch.cuda.is_available() else -1)\n",
        "\n",
        "def augment_text(text):\n",
        "    augmented = paraphraser(text, max_length=100, num_return_sequences=1)\n",
        "    return augmented[0]['generated_text']\n",
        "\n",
        "augmented_data = []\n",
        "for typology in underrepresented_classes:\n",
        "    class_data = data[data['Catégorie'] == typology]\n",
        "    for _, row in class_data.iterrows():\n",
        "        augmented_text = augment_text(row['Combined Text'])\n",
        "        augmented_data.append({'Combined Text': augmented_text, 'Typology': typology})\n",
        "\n",
        "# Append augmented data\n",
        "augmented_df = pd.DataFrame(augmented_data)\n",
        "data = pd.concat([data, augmented_df], ignore_index=True)\n",
        "\n",
        "# Re-encode Typologies Post-Augmentation\n",
        "data['Typology Encoded'] = label_encoder.fit_transform(data['Catégorie'])\n",
        "\n",
        "# Define Models to Test\n",
        "models_to_test = [\"bert-base-multilingual-cased\"]\n",
        "all_model_results = []\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "\n",
        "for model_name in models_to_test:\n",
        "    print(f\"\\nStarting model: {model_name}\")\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name, num_labels=len(label_encoder.classes_)\n",
        "    )\n",
        "\n",
        "    fold_metrics = []\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(data['Combined Text'], data['Typology Encoded'])):\n",
        "        print(f\"\\nStarting Fold {fold + 1} for {model_name}\")\n",
        "\n",
        "        # Split Data\n",
        "        train_texts, val_texts = data['Combined Text'].iloc[train_index], data['Combined Text'].iloc[val_index]\n",
        "        train_labels, val_labels = data['Typology Encoded'].iloc[train_index], data['Typology Encoded'].iloc[val_index]\n",
        "\n",
        "        def tokenize_function(texts):\n",
        "            return tokenizer(list(texts), padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        train_encodings = tokenize_function(train_texts)\n",
        "        val_encodings = tokenize_function(val_texts)\n",
        "\n",
        "        train_labels = torch.tensor(train_labels.values, dtype=torch.long)\n",
        "        val_labels = torch.tensor(val_labels.values, dtype=torch.long)\n",
        "\n",
        "        class Dataset(torch.utils.data.Dataset):\n",
        "            def __init__(self, encodings, labels):\n",
        "                self.encodings = encodings\n",
        "                self.labels = labels\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.labels)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "                item['labels'] = self.labels[idx]\n",
        "                return item\n",
        "\n",
        "        train_dataset = Dataset(train_encodings, train_labels)\n",
        "        val_dataset = Dataset(val_encodings, val_labels)\n",
        "\n",
        "        # Training Arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f\"./results/{model_name}_fold_{fold}\",\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            learning_rate=5e-5,\n",
        "            per_device_train_batch_size=8,\n",
        "            per_device_eval_batch_size=8,\n",
        "            num_train_epochs=3,\n",
        "            weight_decay=0.01,\n",
        "            save_total_limit=2,\n",
        "            load_best_model_at_end=True,\n",
        "        )\n",
        "\n",
        "        # Define Metrics\n",
        "        def compute_metrics(pred):\n",
        "            predictions = pred.predictions.argmax(-1)\n",
        "            labels = pred.label_ids\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "            acc = accuracy_score(labels, predictions)\n",
        "            return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            data_collator=data_collator,\n",
        "            compute_metrics=compute_metrics\n",
        "        )\n",
        "\n",
        "        # Train and Evaluate\n",
        "        trainer.train()\n",
        "        evaluation_results = trainer.evaluate()\n",
        "        print(f\"Fold {fold + 1} Results for {model_name}: {evaluation_results}\")\n",
        "        fold_metrics.append(evaluation_results)\n",
        "\n",
        "    # Compute Average Metrics Across Folds\n",
        "    avg_accuracy = sum([m['eval_accuracy'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_f1 = sum([m['eval_f1'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_precision = sum([m['eval_precision'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_recall = sum([m['eval_recall'] for m in fold_metrics]) / len(fold_metrics)\n",
        "\n",
        "    all_model_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Avg_Accuracy\": avg_accuracy,\n",
        "        \"Avg_F1\": avg_f1,\n",
        "        \"Avg_Precision\": avg_precision,\n",
        "        \"Avg_Recall\": avg_recall\n",
        "    })\n",
        "\n",
        "    # Save Model and Tokenizer\n",
        "    model.save_pretrained(f\"./{model_name}_Combined\")\n",
        "    tokenizer.save_pretrained(f\"./{model_name}_Combined\")\n",
        "\n",
        "# Print Final Results\n",
        "results_df = pd.DataFrame(all_model_results)\n",
        "print(\"\\nFinal Results Across Models:\")\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "xn9V_ng_9MV9",
        "outputId": "1c8c006b-01e4-4d63-9ec1-d42c0d2d1e5f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-22-5d766f04235e>:23: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting model: bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning:\n",
            "\n",
            "The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Fold 1 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnourankhallaf\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.5"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250204_192858-mamsd83f</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/nourankhallaf/huggingface/runs/mamsd83f' target=\"_blank\">./results/bert-base-multilingual-cased_fold_0</a></strong> to <a href='https://wandb.ai/nourankhallaf/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/nourankhallaf/huggingface' target=\"_blank\">https://wandb.ai/nourankhallaf/huggingface</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/nourankhallaf/huggingface/runs/mamsd83f' target=\"_blank\">https://wandb.ai/nourankhallaf/huggingface/runs/mamsd83f</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [123/123 00:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.041606</td>\n",
              "      <td>0.234568</td>\n",
              "      <td>0.089136</td>\n",
              "      <td>0.055022</td>\n",
              "      <td>0.234568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.950629</td>\n",
              "      <td>0.160494</td>\n",
              "      <td>0.096574</td>\n",
              "      <td>0.070483</td>\n",
              "      <td>0.160494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.850037</td>\n",
              "      <td>0.395062</td>\n",
              "      <td>0.299068</td>\n",
              "      <td>0.265834</td>\n",
              "      <td>0.395062</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Results for bert-base-multilingual-cased: {'eval_loss': 1.8500373363494873, 'eval_accuracy': 0.3950617283950617, 'eval_f1': 0.29906826889585514, 'eval_precision': 0.26583392080468105, 'eval_recall': 0.3950617283950617, 'eval_runtime': 0.2964, 'eval_samples_per_second': 273.294, 'eval_steps_per_second': 37.114, 'epoch': 3.0}\n",
            "\n",
            "Starting Fold 2 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [123/123 00:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.693400</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.281227</td>\n",
              "      <td>0.245844</td>\n",
              "      <td>0.407407</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.692833</td>\n",
              "      <td>0.419753</td>\n",
              "      <td>0.331198</td>\n",
              "      <td>0.310897</td>\n",
              "      <td>0.419753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.694503</td>\n",
              "      <td>0.407407</td>\n",
              "      <td>0.357654</td>\n",
              "      <td>0.329094</td>\n",
              "      <td>0.407407</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Results for bert-base-multilingual-cased: {'eval_loss': 1.6928327083587646, 'eval_accuracy': 0.41975308641975306, 'eval_f1': 0.3311975007881441, 'eval_precision': 0.3108969919844624, 'eval_recall': 0.41975308641975306, 'eval_runtime': 0.3312, 'eval_samples_per_second': 244.571, 'eval_steps_per_second': 33.213, 'epoch': 3.0}\n",
            "\n",
            "Starting Fold 3 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [123/123 00:41, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.668443</td>\n",
              "      <td>0.395062</td>\n",
              "      <td>0.308844</td>\n",
              "      <td>0.279822</td>\n",
              "      <td>0.395062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.623549</td>\n",
              "      <td>0.382716</td>\n",
              "      <td>0.285269</td>\n",
              "      <td>0.280342</td>\n",
              "      <td>0.382716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.477432</td>\n",
              "      <td>0.493827</td>\n",
              "      <td>0.419986</td>\n",
              "      <td>0.468398</td>\n",
              "      <td>0.493827</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Results for bert-base-multilingual-cased: {'eval_loss': 1.4774324893951416, 'eval_accuracy': 0.49382716049382713, 'eval_f1': 0.4199855117049102, 'eval_precision': 0.4683981675595931, 'eval_recall': 0.49382716049382713, 'eval_runtime': 0.3145, 'eval_samples_per_second': 257.511, 'eval_steps_per_second': 34.971, 'epoch': 3.0}\n",
            "\n",
            "Starting Fold 4 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [123/123 00:39, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.576184</td>\n",
              "      <td>0.481481</td>\n",
              "      <td>0.417168</td>\n",
              "      <td>0.390837</td>\n",
              "      <td>0.481481</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.417665</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.450988</td>\n",
              "      <td>0.443224</td>\n",
              "      <td>0.518519</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.486526</td>\n",
              "      <td>0.518519</td>\n",
              "      <td>0.461180</td>\n",
              "      <td>0.450901</td>\n",
              "      <td>0.518519</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='11' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Results for bert-base-multilingual-cased: {'eval_loss': 1.417664647102356, 'eval_accuracy': 0.5185185185185185, 'eval_f1': 0.4509882372959807, 'eval_precision': 0.44322413984373765, 'eval_recall': 0.5185185185185185, 'eval_runtime': 0.3262, 'eval_samples_per_second': 248.345, 'eval_steps_per_second': 33.726, 'epoch': 3.0}\n",
            "\n",
            "Starting Fold 5 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='123' max='123' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [123/123 00:38, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.566967</td>\n",
              "      <td>0.487500</td>\n",
              "      <td>0.403552</td>\n",
              "      <td>0.421057</td>\n",
              "      <td>0.487500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.419656</td>\n",
              "      <td>0.512500</td>\n",
              "      <td>0.451595</td>\n",
              "      <td>0.431342</td>\n",
              "      <td>0.512500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.399424</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.473687</td>\n",
              "      <td>0.509843</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='10' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Results for bert-base-multilingual-cased: {'eval_loss': 1.3994238376617432, 'eval_accuracy': 0.525, 'eval_f1': 0.47368742368742367, 'eval_precision': 0.5098432817182817, 'eval_recall': 0.525, 'eval_runtime': 0.2683, 'eval_samples_per_second': 298.128, 'eval_steps_per_second': 37.266, 'epoch': 3.0}\n",
            "\n",
            "Final Results Across Models:\n",
            "                       Model  Avg_Accuracy   Avg_F1  Avg_Precision  Avg_Recall\n",
            "bert-base-multilingual-cased      0.470432 0.394985       0.399639    0.470432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import Trainer\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "saved_model_path = \"./bert-base-multilingual-cased_Combined\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(saved_model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
        "\n",
        "# Reinitialize the Trainer with the loaded model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Make predictions\n",
        "predictions = trainer.predict(val_dataset)\n",
        "\n",
        "# Decode predicted labels\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Decode predicted labels\n",
        "predictions = trainer.predict(val_dataset)\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Debugging output\n",
        "print(\"Predicted classes:\", len(np.unique(predicted_labels)))\n",
        "print(\"Label Encoder classes:\", len(label_encoder.classes_))\n",
        "\n",
        "\n",
        "all_labels = list(range(len(label_encoder.classes_)))\n",
        "target_names = label_encoder.classes_\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(\n",
        "    val_labels,\n",
        "    predicted_labels,\n",
        "    labels=all_labels,\n",
        "    target_names=target_names,\n",
        "    zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "bkFS38IxPjUN",
        "outputId": "5a27e8e2-1e03-4d61-ad7d-24778ddb9c15"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-24-f1c3dccdf36f>:12: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes: 6\n",
            "Label Encoder classes: 10\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "object of type 'float' has no len()",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-f1c3dccdf36f>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;31m# Print the classification report\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m print(classification_report(\n\u001b[0m\u001b[1;32m     45\u001b[0m     \u001b[0mval_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mpredicted_labels\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36mclassification_report\u001b[0;34m(y_true, y_pred, labels, target_names, sample_weight, digits, output_dict, zero_division)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weighted avg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2724\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2725\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:>{width}s} \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" {:>9}\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   2722\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2723\u001b[0m         \u001b[0mlongest_last_line_heading\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"weighted avg\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2724\u001b[0;31m         \u001b[0mname_width\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcn\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcn\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2725\u001b[0m         \u001b[0mwidth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_width\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlongest_last_line_heading\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2726\u001b[0m         \u001b[0mhead_fmt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"{:>{width}s} \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\" {:>9}\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: object of type 'float' has no len()"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "> # Model #2 standard French only\n",
        "\n"
      ],
      "metadata": {
        "id": "IgCPSwm0kTyd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# `**This model only uses the \"Standard\" version of the text and the \"Categories\" for classification.**`\n"
      ],
      "metadata": {
        "id": "5Y4FRY8Jke4E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ** Implementing Weighted Loss for Imbalanced Classes**\n",
        "To **handle imbalanced class representation**, we compute **class weights**:\n",
        "```python\n",
        "class_counts = data['Typology Encoded'].value_counts()\n",
        "class_weights = torch.tensor([1.0 / count * len(data) / 2.0 for count in class_counts])\n",
        "```\n",
        "We define a **custom loss function** to apply these weights:\n",
        "```python\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "```\n",
        "\n",
        "✅ **Why?**  \n",
        "- Prevents **majority classes from dominating** training.\n",
        "- Encourages the model to learn from **underrepresented classes**.\n",
        "\n",
        "\n",
        "> Only Complex\n",
        "\n",
        "## **Summary of Improvements**\n",
        "### ✅ **What We Did and Why?**\n",
        "| **Step** | **What We Did** | **Why?** |\n",
        "|----------|----------------|----------|\n",
        "| **Data Cleaning** | Removed missing values, standardized labels | Ensures consistency and avoids errors |\n",
        "| **Data Augmentation** | Used T5-small to paraphrase rare class samples | Balances class distribution |\n",
        "| **Stratified K-Fold CV** | Used 5-fold cross-validation | Ensures robust evaluation |\n",
        "| **Class Weights** | Adjusted loss function with computed class weights | Prevents bias towards majority classes |\n",
        "| **Training Optimization** | Used mixed precision (`fp16`), gradient checkpointing, and early stopping | Speeds up training and prevents overfitting |\n",
        "| **Performance Logging** | Stored detailed per-epoch, per-fold, and aggregated metrics | Enables deep analysis of model behavior |\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "90Z_u0ZzPHui"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import time\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding,\n",
        "    EarlyStoppingCallback\n",
        ")\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "\n",
        "data = data.dropna(subset=['Version initiale', 'Catégorie'])\n",
        "data['Typology'] = data['Catégorie'].str.replace(\"\\xa0\", \"\").str.replace(\" \", \"\")  # Remove non-breaking spaces and regular spaces from the Typology column\n",
        "from transformers import pipeline\n",
        "\n",
        "paraphraser = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
        "\n",
        "underrepresented_classes = data['Catégorie'].value_counts().tail(3).index.tolist()\n",
        "paraphraser = pipeline(\"text2text-generation\", model=\"t5-small\")\n",
        "\n",
        "def augment_text(text):\n",
        "    augmented = paraphraser(text, max_length=100, num_return_sequences=1)\n",
        "    return augmented[0]['generated_text']\n",
        "\n",
        "# Apply paraphrasing\n",
        "augmented_data = []\n",
        "for typology in underrepresented_classes:\n",
        "    class_data = data[data['Typology'] == typology]\n",
        "    for _, row in class_data.iterrows():\n",
        "        augmented_text = augment_text(row['Version initiale'])\n",
        "        augmented_data.append({'Version initiale': augmented_text, 'Typology': typology})\n",
        "\n",
        "# Append augmented data\n",
        "augmented_df = pd.DataFrame(augmented_data)\n",
        "data = pd.concat([data, augmented_df], ignore_index=True)\n",
        "\n",
        "\n",
        "# Encode Typologies\n",
        "label_encoder = LabelEncoder()\n",
        "data['Typology Encoded'] = label_encoder.fit_transform(data['Typology'])\n",
        "\n",
        "# Calculate class weights\n",
        "class_counts = data['Typology Encoded'].value_counts()\n",
        "class_weights = torch.tensor([1.0 / count * len(data) / 2.0 for count in class_counts])\n",
        "\n",
        "# Prepare Models and Loop Over Them\n",
        "models_to_test = [\n",
        "\n",
        "    \"bert-base-multilingual-cased\",\n",
        "\n",
        "]\n",
        "\n",
        "all_model_results = []\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "detailed_results = []  # Collect per-fold and per-epoch results\n",
        "aggregated_summary = []  # Aggregated summary for each model\n",
        "\n",
        "# Define a Custom Trainer to Incorporate Class Weights\n",
        "class CustomTrainer(Trainer):\n",
        "    def compute_loss(self, model, inputs, return_outputs=False, **kwargs):\n",
        "        labels = inputs.pop(\"labels\")\n",
        "        outputs = model(**inputs)\n",
        "        logits = outputs.logits\n",
        "        loss_fct = torch.nn.CrossEntropyLoss(weight=class_weights.to(logits.device))  # Use class weights\n",
        "        loss = loss_fct(logits, labels)\n",
        "        return (loss, outputs) if return_outputs else loss\n",
        "\n",
        "for model_name in models_to_test:\n",
        "\n",
        "    print(f\"\\nStarting model: {model_name}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(label_encoder.classes_)\n",
        "    )\n",
        "\n",
        "    fold_metrics = []\n",
        "    model_start_time = time.time()\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(data['Version initiale'], data['Typology Encoded'])):\n",
        "        print(f\"\\nStarting Fold {fold + 1} for {model_name}\")\n",
        "\n",
        "        # Split Data\n",
        "        train_texts, val_texts = data['Version initiale'].iloc[train_index], data['Version initiale'].iloc[val_index]\n",
        "        train_labels, val_labels = data['Typology Encoded'].iloc[train_index], data['Typology Encoded'].iloc[val_index]\n",
        "\n",
        "        def tokenize_function(texts):\n",
        "            return tokenizer(list(texts), padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        train_encodings = tokenize_function(train_texts)\n",
        "        val_encodings = tokenize_function(val_texts)\n",
        "\n",
        "        train_labels = torch.tensor(train_labels.values, dtype=torch.long)\n",
        "        val_labels = torch.tensor(val_labels.values, dtype=torch.long)\n",
        "\n",
        "        class Dataset(torch.utils.data.Dataset):\n",
        "            def __init__(self, encodings, labels):\n",
        "                self.encodings = encodings\n",
        "                self.labels = labels\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.labels)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "                item['labels'] = self.labels[idx]\n",
        "                return item\n",
        "\n",
        "        train_dataset = Dataset(train_encodings, train_labels)\n",
        "        val_dataset = Dataset(val_encodings, val_labels)\n",
        "\n",
        "        # Training Arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f\"./results/{model_name}_fold_{fold}\",\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            learning_rate=5e-6,\n",
        "            per_device_train_batch_size=8,\n",
        "            per_device_eval_batch_size=8,\n",
        "            num_train_epochs=5,  # High number; EarlyStopping will handle stopping\n",
        "            weight_decay=0.01,\n",
        "            logging_dir=f\"./logs/{model_name}_fold_{fold}\",\n",
        "            save_total_limit=2,\n",
        "            load_best_model_at_end=True,\n",
        "            gradient_accumulation_steps=1,\n",
        "            fp16=True,\n",
        "            gradient_checkpointing=True,\n",
        "            max_grad_norm=1.0  # Gradient clipping\n",
        "        )\n",
        "\n",
        "        # Define Metrics\n",
        "        def compute_metrics(pred):\n",
        "            predictions = pred.predictions.argmax(-1)\n",
        "            labels = pred.label_ids\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "            accuracy = accuracy_score(labels, predictions)\n",
        "            return {\n",
        "                \"eval_precision\": precision,\n",
        "                \"eval_recall\": recall,\n",
        "                \"eval_f1\": f1,\n",
        "                \"eval_accuracy\": accuracy\n",
        "            }\n",
        "\n",
        "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "        trainer = CustomTrainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            data_collator=data_collator,\n",
        "            compute_metrics=compute_metrics,\n",
        "            callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]  # Early stopping\n",
        "        )\n",
        "\n",
        "        # Train and Evaluate\n",
        "        trainer.train()\n",
        "        for epoch in range(int(trainer.state.epoch)):  # Collect metrics per epoch\n",
        "            epoch_results = trainer.evaluate()\n",
        "            epoch_results.update({\"Model\": model_name, \"Fold\": fold + 1, \"Epoch\": epoch + 1})\n",
        "            detailed_results.append(epoch_results)\n",
        "\n",
        "        evaluation_results = trainer.evaluate()\n",
        "        print(f\"Fold {fold + 1} Results for {model_name}: {evaluation_results}\")\n",
        "\n",
        "        # Collect metrics for the fold\n",
        "        fold_metrics.append(evaluation_results)\n",
        "\n",
        "    # Calculate average metrics across folds\n",
        "    avg_precision = sum([m['eval_precision'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_recall = sum([m['eval_recall'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_f1 = sum([m['eval_f1'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_accuracy = sum([m['eval_accuracy'] for m in fold_metrics]) / len(fold_metrics)\n",
        "\n",
        "    # Calculate training time\n",
        "    model_training_time = time.time() - model_start_time\n",
        "\n",
        "\n",
        "\n",
        "    # Add to final model results\n",
        "    all_model_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Avg_Precision\": avg_precision,\n",
        "        \"Avg_Recall\": avg_recall,\n",
        "        \"Avg_F1\": avg_f1,\n",
        "        \"Avg_Accuracy\": avg_accuracy,\n",
        "        \"Training_Time_Seconds\": model_training_time\n",
        "    })\n",
        "\n",
        "\n",
        "    # Add aggregated summary for this model\n",
        "    aggregated_summary.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Avg_Precision\": avg_precision,\n",
        "        \"Avg_Recall\": avg_recall,\n",
        "        \"Avg_F1\": avg_f1,\n",
        "        \"Avg_Accuracy\": avg_accuracy,\n",
        "        \"Training_Time_Seconds\": model_training_time\n",
        "    })\n",
        "\n",
        "    # Save Model and Tokenizer\n",
        "    model.save_pretrained(f\"./{model_name}_complex\")\n",
        "    tokenizer.save_pretrained(f\"./{model_name}_complex\")\n",
        "\n",
        "# Create a DataFrame for final results\n",
        "final_results_df = pd.DataFrame(all_model_results)\n",
        "final_results_df.to_csv(\"complex_model_results.csv\", index=False)\n",
        "print(\"\\nFinal Results Across Models:\")\n",
        "print(final_results_df)\n",
        "\n",
        "# Create a DataFrame for detailed results\n",
        "detailed_results_df = pd.DataFrame(detailed_results)\n",
        "detailed_results_df.to_csv(\"Complex_detailed_model_results.csv\", index=False)\n",
        "print(\"\\nDetailed Results Per Fold and Epoch:\")\n",
        "print(detailed_results_df)\n",
        "\n",
        "# Create a DataFrame for aggregated summary\n",
        "aggregated_summary_df = pd.DataFrame(aggregated_summary)\n",
        "aggregated_summary_df.to_csv(\"Complex_aggregated_model_summary.csv\", index=False)\n",
        "print(\"\\nAggregated Summary for Each Model:\")\n",
        "print(aggregated_summary_df)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "VHXQ-D42_zLL",
        "outputId": "a826348f-c26f-4d7e-d972-33815240ab20"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-25-20a44b88cec9>:18: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "Device set to use cuda:0\n",
            "Device set to use cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting model: bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Fold 1 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [205/205 01:01, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>2.028586</td>\n",
              "      <td>0.051196</td>\n",
              "      <td>0.148148</td>\n",
              "      <td>0.059914</td>\n",
              "      <td>0.148148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.966519</td>\n",
              "      <td>0.048468</td>\n",
              "      <td>0.160494</td>\n",
              "      <td>0.069212</td>\n",
              "      <td>0.160494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.951368</td>\n",
              "      <td>0.044631</td>\n",
              "      <td>0.160494</td>\n",
              "      <td>0.067530</td>\n",
              "      <td>0.160494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.935617</td>\n",
              "      <td>0.045043</td>\n",
              "      <td>0.160494</td>\n",
              "      <td>0.068055</td>\n",
              "      <td>0.160494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.927495</td>\n",
              "      <td>0.044608</td>\n",
              "      <td>0.160494</td>\n",
              "      <td>0.067934</td>\n",
              "      <td>0.160494</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Results for bert-base-multilingual-cased: {'eval_precision': 0.044608340904637195, 'eval_recall': 0.16049382716049382, 'eval_f1': 0.06793389509438892, 'eval_accuracy': 0.16049382716049382, 'eval_loss': 1.927495002746582, 'eval_runtime': 0.2168, 'eval_samples_per_second': 373.535, 'eval_steps_per_second': 50.727, 'epoch': 5.0}\n",
            "\n",
            "Starting Fold 2 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [205/205 01:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.849895</td>\n",
              "      <td>0.322457</td>\n",
              "      <td>0.259259</td>\n",
              "      <td>0.151339</td>\n",
              "      <td>0.259259</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.837427</td>\n",
              "      <td>0.160963</td>\n",
              "      <td>0.283951</td>\n",
              "      <td>0.167263</td>\n",
              "      <td>0.283951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.819156</td>\n",
              "      <td>0.138889</td>\n",
              "      <td>0.283951</td>\n",
              "      <td>0.170421</td>\n",
              "      <td>0.283951</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.811580</td>\n",
              "      <td>0.371399</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.196975</td>\n",
              "      <td>0.296296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.808863</td>\n",
              "      <td>0.367619</td>\n",
              "      <td>0.283951</td>\n",
              "      <td>0.190509</td>\n",
              "      <td>0.283951</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Results for bert-base-multilingual-cased: {'eval_precision': 0.36761891090056464, 'eval_recall': 0.2839506172839506, 'eval_f1': 0.19050896955137167, 'eval_accuracy': 0.2839506172839506, 'eval_loss': 1.808862566947937, 'eval_runtime': 0.2204, 'eval_samples_per_second': 367.488, 'eval_steps_per_second': 49.906, 'epoch': 5.0}\n",
            "\n",
            "Starting Fold 3 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [205/205 01:03, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.635605</td>\n",
              "      <td>0.267860</td>\n",
              "      <td>0.308642</td>\n",
              "      <td>0.223120</td>\n",
              "      <td>0.308642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.613215</td>\n",
              "      <td>0.313129</td>\n",
              "      <td>0.320988</td>\n",
              "      <td>0.234257</td>\n",
              "      <td>0.320988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.587922</td>\n",
              "      <td>0.345628</td>\n",
              "      <td>0.308642</td>\n",
              "      <td>0.224164</td>\n",
              "      <td>0.308642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.573130</td>\n",
              "      <td>0.327863</td>\n",
              "      <td>0.296296</td>\n",
              "      <td>0.208227</td>\n",
              "      <td>0.296296</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.568348</td>\n",
              "      <td>0.331060</td>\n",
              "      <td>0.308642</td>\n",
              "      <td>0.222850</td>\n",
              "      <td>0.308642</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Results for bert-base-multilingual-cased: {'eval_precision': 0.3310596385309029, 'eval_recall': 0.30864197530864196, 'eval_f1': 0.22284968118301451, 'eval_accuracy': 0.30864197530864196, 'eval_loss': 1.5683480501174927, 'eval_runtime': 0.2105, 'eval_samples_per_second': 384.887, 'eval_steps_per_second': 52.269, 'epoch': 5.0}\n",
            "\n",
            "Starting Fold 4 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [205/205 01:05, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.485601</td>\n",
              "      <td>0.275844</td>\n",
              "      <td>0.419753</td>\n",
              "      <td>0.306773</td>\n",
              "      <td>0.419753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.455188</td>\n",
              "      <td>0.351551</td>\n",
              "      <td>0.432099</td>\n",
              "      <td>0.329693</td>\n",
              "      <td>0.432099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.479799</td>\n",
              "      <td>0.256687</td>\n",
              "      <td>0.395062</td>\n",
              "      <td>0.284850</td>\n",
              "      <td>0.395062</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.472227</td>\n",
              "      <td>0.373968</td>\n",
              "      <td>0.419753</td>\n",
              "      <td>0.318539</td>\n",
              "      <td>0.419753</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.462958</td>\n",
              "      <td>0.369316</td>\n",
              "      <td>0.419753</td>\n",
              "      <td>0.316838</td>\n",
              "      <td>0.419753</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='66' max='11' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [11/11 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Results for bert-base-multilingual-cased: {'eval_precision': 0.35155103121314946, 'eval_recall': 0.43209876543209874, 'eval_f1': 0.32969290485630354, 'eval_accuracy': 0.43209876543209874, 'eval_loss': 1.455188274383545, 'eval_runtime': 0.2399, 'eval_samples_per_second': 337.652, 'eval_steps_per_second': 45.854, 'epoch': 5.0}\n",
            "\n",
            "Starting Fold 5 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='205' max='205' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [205/205 01:06, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "      <th>F1</th>\n",
              "      <th>Accuracy</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.325702</td>\n",
              "      <td>0.487185</td>\n",
              "      <td>0.462500</td>\n",
              "      <td>0.365969</td>\n",
              "      <td>0.462500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.306055</td>\n",
              "      <td>0.487009</td>\n",
              "      <td>0.475000</td>\n",
              "      <td>0.387225</td>\n",
              "      <td>0.475000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.293278</td>\n",
              "      <td>0.507679</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.446433</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.286679</td>\n",
              "      <td>0.506673</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.446919</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.277338</td>\n",
              "      <td>0.506673</td>\n",
              "      <td>0.525000</td>\n",
              "      <td>0.446919</td>\n",
              "      <td>0.525000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='60' max='10' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [10/10 00:01]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Results for bert-base-multilingual-cased: {'eval_precision': 0.506672932330827, 'eval_recall': 0.525, 'eval_f1': 0.44691870410948376, 'eval_accuracy': 0.525, 'eval_loss': 1.277337670326233, 'eval_runtime': 0.2004, 'eval_samples_per_second': 399.187, 'eval_steps_per_second': 49.898, 'epoch': 5.0}\n",
            "\n",
            "Final Results Across Models:\n",
            "                          Model  Avg_Precision  Avg_Recall    Avg_F1  \\\n",
            "0  bert-base-multilingual-cased       0.320302    0.342037  0.251581   \n",
            "\n",
            "   Avg_Accuracy  Training_Time_Seconds  \n",
            "0      0.342037              331.05384  \n",
            "\n",
            "Detailed Results Per Fold and Epoch:\n",
            "    eval_precision  eval_recall   eval_f1  eval_accuracy  eval_loss  \\\n",
            "0         0.044608     0.160494  0.067934       0.160494   1.927495   \n",
            "1         0.044608     0.160494  0.067934       0.160494   1.927495   \n",
            "2         0.044608     0.160494  0.067934       0.160494   1.927495   \n",
            "3         0.044608     0.160494  0.067934       0.160494   1.927495   \n",
            "4         0.044608     0.160494  0.067934       0.160494   1.927495   \n",
            "5         0.367619     0.283951  0.190509       0.283951   1.808863   \n",
            "6         0.367619     0.283951  0.190509       0.283951   1.808863   \n",
            "7         0.367619     0.283951  0.190509       0.283951   1.808863   \n",
            "8         0.367619     0.283951  0.190509       0.283951   1.808863   \n",
            "9         0.367619     0.283951  0.190509       0.283951   1.808863   \n",
            "10        0.331060     0.308642  0.222850       0.308642   1.568348   \n",
            "11        0.331060     0.308642  0.222850       0.308642   1.568348   \n",
            "12        0.331060     0.308642  0.222850       0.308642   1.568348   \n",
            "13        0.331060     0.308642  0.222850       0.308642   1.568348   \n",
            "14        0.331060     0.308642  0.222850       0.308642   1.568348   \n",
            "15        0.351551     0.432099  0.329693       0.432099   1.455188   \n",
            "16        0.351551     0.432099  0.329693       0.432099   1.455188   \n",
            "17        0.351551     0.432099  0.329693       0.432099   1.455188   \n",
            "18        0.351551     0.432099  0.329693       0.432099   1.455188   \n",
            "19        0.351551     0.432099  0.329693       0.432099   1.455188   \n",
            "20        0.506673     0.525000  0.446919       0.525000   1.277338   \n",
            "21        0.506673     0.525000  0.446919       0.525000   1.277338   \n",
            "22        0.506673     0.525000  0.446919       0.525000   1.277338   \n",
            "23        0.506673     0.525000  0.446919       0.525000   1.277338   \n",
            "24        0.506673     0.525000  0.446919       0.525000   1.277338   \n",
            "\n",
            "    eval_runtime  eval_samples_per_second  eval_steps_per_second  epoch  \\\n",
            "0         0.2473                  327.548                 44.482    5.0   \n",
            "1         0.2322                  348.769                 47.364    5.0   \n",
            "2         0.2530                  320.100                 43.470    5.0   \n",
            "3         0.2554                  317.132                 43.067    5.0   \n",
            "4         0.2141                  378.295                 51.373    5.0   \n",
            "5         0.2263                  357.866                 48.599    5.0   \n",
            "6         0.2082                  388.986                 52.825    5.0   \n",
            "7         0.2063                  392.686                 53.328    5.0   \n",
            "8         0.2164                  374.344                 50.837    5.0   \n",
            "9         0.2098                  386.148                 52.440    5.0   \n",
            "10        0.2342                  345.787                 46.959    5.0   \n",
            "11        0.2038                  397.506                 53.982    5.0   \n",
            "12        0.1944                  416.652                 56.582    5.0   \n",
            "13        0.2005                  403.986                 54.862    5.0   \n",
            "14        0.2018                  401.482                 54.522    5.0   \n",
            "15        0.2761                  293.424                 39.848    5.0   \n",
            "16        0.2649                  305.735                 41.520    5.0   \n",
            "17        0.2623                  308.780                 41.933    5.0   \n",
            "18        0.2305                  351.465                 47.730    5.0   \n",
            "19        0.2263                  357.878                 48.601    5.0   \n",
            "20        0.2206                  362.642                 45.330    5.0   \n",
            "21        0.2054                  389.390                 48.674    5.0   \n",
            "22        0.1914                  418.004                 52.250    5.0   \n",
            "23        0.1874                  426.839                 53.355    5.0   \n",
            "24        0.1870                  427.727                 53.466    5.0   \n",
            "\n",
            "                           Model  Fold  Epoch  \n",
            "0   bert-base-multilingual-cased     1      1  \n",
            "1   bert-base-multilingual-cased     1      2  \n",
            "2   bert-base-multilingual-cased     1      3  \n",
            "3   bert-base-multilingual-cased     1      4  \n",
            "4   bert-base-multilingual-cased     1      5  \n",
            "5   bert-base-multilingual-cased     2      1  \n",
            "6   bert-base-multilingual-cased     2      2  \n",
            "7   bert-base-multilingual-cased     2      3  \n",
            "8   bert-base-multilingual-cased     2      4  \n",
            "9   bert-base-multilingual-cased     2      5  \n",
            "10  bert-base-multilingual-cased     3      1  \n",
            "11  bert-base-multilingual-cased     3      2  \n",
            "12  bert-base-multilingual-cased     3      3  \n",
            "13  bert-base-multilingual-cased     3      4  \n",
            "14  bert-base-multilingual-cased     3      5  \n",
            "15  bert-base-multilingual-cased     4      1  \n",
            "16  bert-base-multilingual-cased     4      2  \n",
            "17  bert-base-multilingual-cased     4      3  \n",
            "18  bert-base-multilingual-cased     4      4  \n",
            "19  bert-base-multilingual-cased     4      5  \n",
            "20  bert-base-multilingual-cased     5      1  \n",
            "21  bert-base-multilingual-cased     5      2  \n",
            "22  bert-base-multilingual-cased     5      3  \n",
            "23  bert-base-multilingual-cased     5      4  \n",
            "24  bert-base-multilingual-cased     5      5  \n",
            "\n",
            "Aggregated Summary for Each Model:\n",
            "                          Model  Avg_Precision  Avg_Recall    Avg_F1  \\\n",
            "0  bert-base-multilingual-cased       0.320302    0.342037  0.251581   \n",
            "\n",
            "   Avg_Accuracy  Training_Time_Seconds  \n",
            "0      0.342037              331.05384  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import Trainer\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "saved_model_path = \"./bert-base-multilingual-cased_complex\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(saved_model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
        "\n",
        "# Reinitialize the Trainer with the loaded model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Make predictions\n",
        "predictions = trainer.predict(val_dataset)\n",
        "\n",
        "# Decode predicted labels\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Decode predicted labels\n",
        "predictions = trainer.predict(val_dataset)\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Debugging output\n",
        "print(\"Predicted classes:\", len(np.unique(predicted_labels)))\n",
        "print(\"Label Encoder classes:\", len(label_encoder.classes_))\n",
        "\n",
        "\n",
        "all_labels = list(range(len(label_encoder.classes_)))\n",
        "target_names = label_encoder.classes_\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(\n",
        "    val_labels,\n",
        "    predicted_labels,\n",
        "    labels=all_labels,\n",
        "    target_names=target_names,\n",
        "    zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "tS9KJfBXSNZY",
        "outputId": "ad2feea2-373e-4346-ff5e-0e6a793ed749"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-26-a57bd6d5f1be>:12: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes: 6\n",
            "Label Encoder classes: 9\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Compression       0.00      0.00      0.00         6\n",
            "  Explanation       1.00      0.28      0.43        18\n",
            "   Modulation       0.00      0.00      0.00         9\n",
            "     Omission       0.50      0.80      0.62         5\n",
            " Substitution       0.43      0.60      0.50        15\n",
            "     Synonymy       0.00      0.00      0.00         1\n",
            "    Syntactic       0.47      0.90      0.62        10\n",
            "Transcription       0.58      1.00      0.73        11\n",
            "Transposition       0.50      0.80      0.62         5\n",
            "\n",
            "     accuracy                           0.53        80\n",
            "    macro avg       0.39      0.49      0.39        80\n",
            " weighted avg       0.51      0.53      0.45        80\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "> # Model #3 No Data-Augmentation"
      ],
      "metadata": {
        "id": "7bN3_gI1mg5o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "This script performs **text classification** using transformer-based models to categorize text into different typologies.  \n",
        "\n",
        "It follows these key steps:\n",
        "1. **Data Preparation**: Combining both Standard and Easy-to-Read versions of the text and its respective **categories** into a single input format.\n",
        "2. **Model Training**: Fine-tuning transformer-based models (e.g., **BERT**) using stratified k-fold cross-validation.\n",
        "3. **Evaluation**: Assessing model performance with **accuracy, F1-score, precision, and recall**.\n",
        "4. **Model Saving**: Storing the trained models for future inference.\n",
        "\n",
        "Unlike other versions, this approach does **not apply data augmentation** for classification. The model is trained with a **stratified k-fold cross-validation strategy** to ensure robust evaluation across different data splits.\n",
        "------\n"
      ],
      "metadata": {
        "id": "6uetGgqvl9gU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    AutoModelForSequenceClassification,\n",
        "    TrainingArguments,\n",
        "    Trainer,\n",
        "    DataCollatorWithPadding\n",
        ")\n",
        "from sklearn.metrics import precision_recall_fscore_support, accuracy_score\n",
        "\n",
        "# Combine \"Standard English\" and \"E2R Version\" for input\n",
        "data['Combined Text'] = data.apply(\n",
        "    lambda row: f\"Standard French: {row['Version initiale']} [SEP] Easy-to-Read: {row['Version retraitée']}\", axis=1\n",
        ")\n",
        "data = data.dropna(subset=['Combined Text', 'Catégorie'])\n",
        "\n",
        "# Encode Typologies\n",
        "label_encoder = LabelEncoder()\n",
        "data['Typology Encoded'] = label_encoder.fit_transform(data['Catégorie'])\n",
        "\n",
        "# Step 4: Prepare Models and Loop Over Them\n",
        "models_to_test = [\n",
        "    \"bert-base-multilingual-cased\",\n",
        "]\n",
        "\n",
        "all_model_results = []\n",
        "skf = StratifiedKFold(n_splits=5)\n",
        "for model_name in models_to_test:\n",
        "    print(f\"\\nStarting model: {model_name}\")\n",
        "\n",
        "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "    model = AutoModelForSequenceClassification.from_pretrained(\n",
        "        model_name,\n",
        "        num_labels=len(label_encoder.classes_)\n",
        "    )\n",
        "\n",
        "    fold_metrics = []\n",
        "\n",
        "    for fold, (train_index, val_index) in enumerate(skf.split(data['Combined Text'], data['Typology Encoded'])):\n",
        "        print(f\"\\nStarting Fold {fold + 1} for {model_name}\")\n",
        "\n",
        "        # Split Data\n",
        "        train_texts, val_texts = data['Combined Text'].iloc[train_index], data['Combined Text'].iloc[val_index]\n",
        "        train_labels, val_labels = data['Typology Encoded'].iloc[train_index], data['Typology Encoded'].iloc[val_index]\n",
        "\n",
        "        def tokenize_function(texts):\n",
        "            return tokenizer(list(texts), padding=True, truncation=True, max_length=512)\n",
        "\n",
        "        train_encodings = tokenize_function(train_texts)\n",
        "        val_encodings = tokenize_function(val_texts)\n",
        "\n",
        "        train_labels = torch.tensor(train_labels.values, dtype=torch.long)\n",
        "        val_labels = torch.tensor(val_labels.values, dtype=torch.long)\n",
        "\n",
        "        class Dataset(torch.utils.data.Dataset):\n",
        "            def __init__(self, encodings, labels):\n",
        "                self.encodings = encodings\n",
        "                self.labels = labels\n",
        "\n",
        "            def __len__(self):\n",
        "                return len(self.labels)\n",
        "\n",
        "            def __getitem__(self, idx):\n",
        "                item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "                item['labels'] = self.labels[idx]\n",
        "                return item\n",
        "\n",
        "        train_dataset = Dataset(train_encodings, train_labels)\n",
        "        val_dataset = Dataset(val_encodings, val_labels)\n",
        "\n",
        "        # Training Arguments\n",
        "        training_args = TrainingArguments(\n",
        "            output_dir=f\"./results/{model_name}_fold_{fold}\",\n",
        "            evaluation_strategy=\"epoch\",\n",
        "            save_strategy=\"epoch\",\n",
        "            learning_rate=5e-5,\n",
        "            per_device_train_batch_size=16,\n",
        "            per_device_eval_batch_size=16,\n",
        "            num_train_epochs=3,\n",
        "            weight_decay=0.01,\n",
        "            logging_dir=f\"./logs/{model_name}_fold_{fold}\",\n",
        "            save_total_limit=2,\n",
        "            load_best_model_at_end=True,\n",
        "            max_grad_norm=1.0\n",
        "        )\n",
        "\n",
        "        # Define Metrics\n",
        "        def compute_metrics(pred):\n",
        "            predictions = pred.predictions.argmax(-1)\n",
        "            labels = pred.label_ids\n",
        "            precision, recall, f1, _ = precision_recall_fscore_support(labels, predictions, average='weighted')\n",
        "            acc = accuracy_score(labels, predictions)\n",
        "            return {\"accuracy\": acc, \"f1\": f1, \"precision\": precision, \"recall\": recall}\n",
        "\n",
        "        data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "        trainer = Trainer(\n",
        "            model=model,\n",
        "            args=training_args,\n",
        "            train_dataset=train_dataset,\n",
        "            eval_dataset=val_dataset,\n",
        "            data_collator=data_collator,\n",
        "            compute_metrics=compute_metrics\n",
        "        )\n",
        "\n",
        "        # Train and Evaluate\n",
        "        trainer.train()\n",
        "        evaluation_results = trainer.evaluate()\n",
        "        print(f\"Fold {fold + 1} Results for {model_name}: {evaluation_results}\")\n",
        "\n",
        "        # Collect metrics for the fold\n",
        "        fold_metrics.append(evaluation_results)\n",
        "\n",
        "    # Calculate average metrics across folds\n",
        "    avg_accuracy = sum([m['eval_accuracy'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_f1 = sum([m['eval_f1'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_precision = sum([m['eval_precision'] for m in fold_metrics]) / len(fold_metrics)\n",
        "    avg_recall = sum([m['eval_recall'] for m in fold_metrics]) / len(fold_metrics)\n",
        "\n",
        "    # Add to final model results\n",
        "    all_model_results.append({\n",
        "        \"Model\": model_name,\n",
        "        \"Avg_Accuracy\": avg_accuracy,\n",
        "        \"Avg_F1\": avg_f1,\n",
        "        \"Avg_Precision\": avg_precision,\n",
        "        \"Avg_Recall\": avg_recall\n",
        "    })\n",
        "\n",
        "    # Save Model and Tokenizer\n",
        "    model.save_pretrained(f\"./{model_name}_combined-non-aug\")\n",
        "    tokenizer.save_pretrained(f\"./{model_name}_combined-non-aug\")\n",
        "\n",
        "# Step 3: Print Final Table of Results\n",
        "import pandas as pd\n",
        "results_df = pd.DataFrame(all_model_results)\n",
        "print(\"\\nFinal Results Across Models:\")\n",
        "print(results_df.to_string(index=False))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "g6XFgkDuCMED",
        "outputId": "cfeb07af-ffc1-4abd-8c66-cc6bf557e772"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting model: bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-27-1b65f5f5d80d>:22: SettingWithCopyWarning:\n",
            "\n",
            "\n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "\n",
            "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_split.py:805: UserWarning:\n",
            "\n",
            "The least populated class in y has only 3 members, which is less than n_splits=5.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Starting Fold 1 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:35, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.928143</td>\n",
              "      <td>0.256757</td>\n",
              "      <td>0.186289</td>\n",
              "      <td>0.165125</td>\n",
              "      <td>0.256757</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.680644</td>\n",
              "      <td>0.378378</td>\n",
              "      <td>0.231660</td>\n",
              "      <td>0.172761</td>\n",
              "      <td>0.378378</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.598781</td>\n",
              "      <td>0.405405</td>\n",
              "      <td>0.258221</td>\n",
              "      <td>0.205753</td>\n",
              "      <td>0.405405</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 1 Results for bert-base-multilingual-cased: {'eval_loss': 1.5987812280654907, 'eval_accuracy': 0.40540540540540543, 'eval_f1': 0.2582207207207207, 'eval_precision': 0.20575304181861562, 'eval_recall': 0.40540540540540543, 'eval_runtime': 0.21, 'eval_samples_per_second': 352.358, 'eval_steps_per_second': 23.808, 'epoch': 3.0}\n",
            "\n",
            "Starting Fold 2 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:31, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.659722</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.250356</td>\n",
              "      <td>0.202505</td>\n",
              "      <td>0.351351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.754901</td>\n",
              "      <td>0.351351</td>\n",
              "      <td>0.254211</td>\n",
              "      <td>0.208151</td>\n",
              "      <td>0.351351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.728228</td>\n",
              "      <td>0.324324</td>\n",
              "      <td>0.226759</td>\n",
              "      <td>0.183840</td>\n",
              "      <td>0.324324</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 2 Results for bert-base-multilingual-cased: {'eval_loss': 1.6597224473953247, 'eval_accuracy': 0.35135135135135137, 'eval_f1': 0.25035611092582605, 'eval_precision': 0.20250534815752208, 'eval_recall': 0.35135135135135137, 'eval_runtime': 0.2836, 'eval_samples_per_second': 260.976, 'eval_steps_per_second': 17.634, 'epoch': 3.0}\n",
            "\n",
            "Starting Fold 3 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.532570</td>\n",
              "      <td>0.459459</td>\n",
              "      <td>0.375405</td>\n",
              "      <td>0.456053</td>\n",
              "      <td>0.459459</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.544921</td>\n",
              "      <td>0.445946</td>\n",
              "      <td>0.358423</td>\n",
              "      <td>0.347583</td>\n",
              "      <td>0.445946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.431475</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>0.456071</td>\n",
              "      <td>0.436503</td>\n",
              "      <td>0.513514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 3 Results for bert-base-multilingual-cased: {'eval_loss': 1.4314748048782349, 'eval_accuracy': 0.5135135135135135, 'eval_f1': 0.4560714652033438, 'eval_precision': 0.4365026865026865, 'eval_recall': 0.5135135135135135, 'eval_runtime': 0.248, 'eval_samples_per_second': 298.339, 'eval_steps_per_second': 20.158, 'epoch': 3.0}\n",
            "\n",
            "Starting Fold 4 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:36, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.585442</td>\n",
              "      <td>0.472973</td>\n",
              "      <td>0.409037</td>\n",
              "      <td>0.394652</td>\n",
              "      <td>0.472973</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.443434</td>\n",
              "      <td>0.418919</td>\n",
              "      <td>0.347301</td>\n",
              "      <td>0.352477</td>\n",
              "      <td>0.418919</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.372185</td>\n",
              "      <td>0.513514</td>\n",
              "      <td>0.477856</td>\n",
              "      <td>0.517577</td>\n",
              "      <td>0.513514</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/transformers/training_args.py:1575: FutureWarning:\n",
            "\n",
            "`evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 4 Results for bert-base-multilingual-cased: {'eval_loss': 1.3721853494644165, 'eval_accuracy': 0.5135135135135135, 'eval_f1': 0.4778559206476826, 'eval_precision': 0.5175773599686643, 'eval_recall': 0.5135135135135135, 'eval_runtime': 0.2688, 'eval_samples_per_second': 275.303, 'eval_steps_per_second': 18.602, 'epoch': 3.0}\n",
            "\n",
            "Starting Fold 5 for bert-base-multilingual-cased\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='57' max='57' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [57/57 00:33, Epoch 3/3]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.191823</td>\n",
              "      <td>0.567568</td>\n",
              "      <td>0.505553</td>\n",
              "      <td>0.481086</td>\n",
              "      <td>0.567568</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.179004</td>\n",
              "      <td>0.581081</td>\n",
              "      <td>0.536886</td>\n",
              "      <td>0.511486</td>\n",
              "      <td>0.581081</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>No log</td>\n",
              "      <td>1.218703</td>\n",
              "      <td>0.581081</td>\n",
              "      <td>0.537072</td>\n",
              "      <td>0.524089</td>\n",
              "      <td>0.581081</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='5' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [5/5 00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning:\n",
            "\n",
            "Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fold 5 Results for bert-base-multilingual-cased: {'eval_loss': 1.179004192352295, 'eval_accuracy': 0.581081081081081, 'eval_f1': 0.5368855697803067, 'eval_precision': 0.5114864864864865, 'eval_recall': 0.581081081081081, 'eval_runtime': 0.2107, 'eval_samples_per_second': 351.177, 'eval_steps_per_second': 23.728, 'epoch': 3.0}\n",
            "\n",
            "Final Results Across Models:\n",
            "                       Model  Avg_Accuracy   Avg_F1  Avg_Precision  Avg_Recall\n",
            "bert-base-multilingual-cased      0.472973 0.395878       0.374765    0.472973\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "from transformers import Trainer\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Load the saved model and tokenizer\n",
        "saved_model_path = \"./bert-base-multilingual-cased_combined-non-aug\"\n",
        "model = AutoModelForSequenceClassification.from_pretrained(saved_model_path)\n",
        "tokenizer = AutoTokenizer.from_pretrained(saved_model_path)\n",
        "\n",
        "# Reinitialize the Trainer with the loaded model\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        ")\n",
        "\n",
        "# Evaluate the model\n",
        "trainer.evaluate()\n",
        "\n",
        "# Make predictions\n",
        "predictions = trainer.predict(val_dataset)\n",
        "\n",
        "# Decode predicted labels\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "import numpy as np\n",
        "\n",
        "# Decode predicted labels\n",
        "predictions = trainer.predict(val_dataset)\n",
        "predicted_labels = np.argmax(predictions.predictions, axis=1)\n",
        "\n",
        "# Debugging output\n",
        "print(\"Predicted classes:\", len(np.unique(predicted_labels)))\n",
        "print(\"Label Encoder classes:\", len(label_encoder.classes_))\n",
        "\n",
        "\n",
        "all_labels = list(range(len(label_encoder.classes_)))\n",
        "target_names = label_encoder.classes_\n",
        "\n",
        "# Print the classification report\n",
        "print(classification_report(\n",
        "    val_labels,\n",
        "    predicted_labels,\n",
        "    labels=all_labels,\n",
        "    target_names=target_names,\n",
        "    zero_division=0\n",
        "))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "-sJHbdA7NBT1",
        "outputId": "6f2c02b5-c711-4918-86c3-71c56077b80f"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-28-b8dd40c23323>:12: FutureWarning:\n",
            "\n",
            "`tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted classes: 5\n",
            "Label Encoder classes: 9\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "  Compression       0.00      0.00      0.00         3\n",
            "  Explanation       0.60      0.67      0.63        18\n",
            "   Modulation       0.40      0.50      0.44         8\n",
            "     Omission       0.00      0.00      0.00         3\n",
            " Substitution       0.44      0.73      0.55        15\n",
            "     Synonymy       0.00      0.00      0.00         1\n",
            "    Syntactic       0.62      0.50      0.56        10\n",
            "Transcription       1.00      1.00      1.00        11\n",
            "Transposition       0.00      0.00      0.00         5\n",
            "\n",
            "     accuracy                           0.58        74\n",
            "    macro avg       0.34      0.38      0.35        74\n",
            " weighted avg       0.51      0.58      0.54        74\n",
            "\n"
          ]
        }
      ]
    }
  ]
}